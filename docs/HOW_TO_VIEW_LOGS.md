# å¦‚ä½•æŸ¥çœ‹æ—¥å¿—è¾“å‡º

## ğŸ“‹ æ¦‚è¿°

LightMirrors çš„é‡åŒ–æ—¥å¿—ä¼šè¾“å‡ºåˆ°ä¸¤ä¸ªåœ°æ–¹ï¼š
1. **æ§åˆ¶å°æ—¥å¿—**ï¼šå®æ—¶è¾“å‡ºåˆ° Docker å®¹å™¨æ—¥å¿—
2. **JSON æ–‡ä»¶**ï¼šæŒä¹…åŒ–ä¿å­˜åˆ° `data/metrics/metrics.json`

---

## ğŸ–¥ï¸ æ–¹æ³• 1ï¼šæŸ¥çœ‹å®æ—¶æ§åˆ¶å°æ—¥å¿—

### Windows (PowerShell)

```powershell
# æŸ¥çœ‹æ‰€æœ‰å®æ—¶æ—¥å¿—
docker-compose logs -f lightmirrors

# åªæŸ¥çœ‹é‡åŒ–æŒ‡æ ‡æ—¥å¿—
docker-compose logs -f lightmirrors | Select-String "METRICS"

# æŸ¥çœ‹æœ€è¿‘ 100 æ¡æ—¥å¿—
docker-compose logs --tail 100 lightmirrors

# åªçœ‹æœ€è¿‘ 50 æ¡ METRICS æ—¥å¿—
docker-compose logs --tail 100 lightmirrors | Select-String "METRICS"
```

### Linux/Mac (Bash)

```bash
# æŸ¥çœ‹æ‰€æœ‰å®æ—¶æ—¥å¿—
docker-compose logs -f lightmirrors

# åªæŸ¥çœ‹é‡åŒ–æŒ‡æ ‡æ—¥å¿—
docker-compose logs -f lightmirrors | grep METRICS

# æŸ¥çœ‹æœ€è¿‘ 100 æ¡æ—¥å¿—
docker-compose logs --tail 100 lightmirrors

# åªçœ‹æœ€è¿‘ 50 æ¡ METRICS æ—¥å¿—
docker-compose logs --tail 100 lightmirrors | grep METRICS
```

### æ—¥å¿—è¾“å‡ºç¤ºä¾‹

```
lightmirrors  | 2025-10-31 11:31:00 - mirrorsrun.metrics - INFO - [METRICS] Cache HIT | requests-2.28.0.whl | Total: 0.003s | Size: 0.06MB
lightmirrors  | 2025-10-31 11:31:05 - mirrorsrun.metrics - INFO - [METRICS] Cache MISS | numpy-1.24.0.whl | Aria2: 10.2s @ 1.16MB/s | Total: 12.5s | Size: 14.53MB
lightmirrors  | 2025-10-31 11:31:05 - mirrorsrun.metrics - INFO - [METRICS] Aria2 download completed: numpy-1.24.0.whl
```

---

## ğŸ“ æ–¹æ³• 2ï¼šæŸ¥çœ‹ JSON æ•°æ®æ–‡ä»¶

### æŸ¥çœ‹æ–‡ä»¶ä½ç½®

JSON æ•°æ®æ–‡ä»¶åœ¨ï¼š
```
data/metrics/metrics.json
```

### Windows

```powershell
# æŸ¥çœ‹åŸå§‹ JSON
Get-Content data\metrics\metrics.json

# æ ¼å¼åŒ–æŸ¥çœ‹ï¼ˆè½¬æ¢ä¸º PowerShell å¯¹è±¡ï¼‰
Get-Content data\metrics\metrics.json | ConvertFrom-Json | Format-List

# åªçœ‹æœ€å 5 æ¡è®°å½•
Get-Content data\metrics\metrics.json | ConvertFrom-Json | Select-Object -Last 5 | Format-List

# åœ¨è®°äº‹æœ¬ä¸­æ‰“å¼€
notepad data\metrics\metrics.json

# åœ¨ VS Code ä¸­æ‰“å¼€
code data\metrics\metrics.json
```

### Linux/Mac

```bash
# æŸ¥çœ‹åŸå§‹ JSON
cat data/metrics/metrics.json

# æ ¼å¼åŒ–æŸ¥çœ‹ï¼ˆéœ€è¦ jqï¼‰
cat data/metrics/metrics.json | jq '.'

# åªçœ‹æœ€å 5 æ¡è®°å½•
cat data/metrics/metrics.json | jq '.[-5:]'

# æŸ¥çœ‹ç‰¹å®šåŒ…
cat data/metrics/metrics.json | jq '.[] | select(.package_name | contains("numpy"))'

# åœ¨ç¼–è¾‘å™¨ä¸­æ‰“å¼€
vim data/metrics/metrics.json
nano data/metrics/metrics.json
```

### JSON æ•°æ®æ ¼å¼

```json
[
  {
    "timestamp": "2025-10-31T11:31:01.331884Z",
    "url": "https://pypi.tuna.tsinghua.edu.cn/packages/.../shapely-2.1.2.whl",
    "package_name": "shapely-2.1.2-cp312-cp312-win_amd64.whl",
    "file_size_mb": 1.64,
    "cache_hit": false,
    "total_time": 1.035,
    "status": "success",
    "aria2_download_speed_mbs": 1.64,
    "aria2_download_time": 1.001,
    "client_receive_speed_mbs": 1.59
  },
  {
    "timestamp": "2025-10-31T11:31:01.397012Z",
    "url": "https://pypi.tuna.tsinghua.edu.cn/packages/.../shapely-2.1.2.whl",
    "package_name": "shapely-2.1.2-cp312-cp312-win_amd64.whl",
    "file_size_mb": 1.64,
    "cache_hit": true,
    "total_time": 0.002,
    "status": "success"
  }
]
```

**å­—æ®µè¯´æ˜ï¼š**
- `file_size_mb`: æ–‡ä»¶å¤§å°ï¼Œå•ä½ **MB**
- `aria2_download_speed_mbs`: Aria2 ä¸‹è½½é€Ÿåº¦ï¼Œå•ä½ **MB/s**
- `client_receive_speed_mbs`: å®¢æˆ·ç«¯æ¥æ”¶é€Ÿåº¦ï¼Œå•ä½ **MB/s**
- ç¼“å­˜å‘½ä¸­æ—¶ä¸åŒ…å«é€Ÿåº¦å­—æ®µ

---

## ğŸ” æ–¹æ³• 3ï¼šåœ¨å®¹å™¨å†…æŸ¥çœ‹æ—¥å¿—

### è¿›å…¥å®¹å™¨

```bash
# è¿›å…¥ lightmirrors å®¹å™¨
docker-compose exec lightmirrors sh

# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
cat /app/data/metrics.json

# é€€å‡ºå®¹å™¨
exit
```

---

## ğŸ“Š æ–¹æ³• 4ï¼šä½¿ç”¨ Python åˆ†ææ—¥å¿—

### å®‰è£…ä¾èµ–

```bash
pip install pandas
```

### åˆ›å»ºåˆ†æè„šæœ¬

åˆ›å»º `view_metrics.py`:

```python
import json
import pandas as pd

# è¯»å–æ•°æ®
with open('data/metrics/metrics.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

df = pd.DataFrame(data)

print(f"æ€»è®°å½•æ•°: {len(df)}")
print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} è‡³ {df['timestamp'].max()}")
print()

# ç¼“å­˜å‘½ä¸­ç»Ÿè®¡
print("=== ç¼“å­˜ç»Ÿè®¡ ===")
cache_hit_count = df['cache_hit'].sum()
cache_miss_count = len(df) - cache_hit_count
cache_hit_rate = cache_hit_count / len(df) * 100
print(f"ç¼“å­˜å‘½ä¸­: {cache_hit_count} æ¬¡ ({cache_hit_rate:.1f}%)")
print(f"ç¼“å­˜æœªå‘½ä¸­: {cache_miss_count} æ¬¡")
print()

# ä¸‹è½½é€Ÿåº¦ç»Ÿè®¡
print("=== ä¸‹è½½é€Ÿåº¦ç»Ÿè®¡ ===")
downloads = df[df['aria2_download_speed_mbs'].notna()]
if len(downloads) > 0:
    print(f"å¹³å‡ä¸‹è½½é€Ÿåº¦: {downloads['aria2_download_speed_mbs'].mean():.2f} MB/s")
    print(f"æœ€å¿«ä¸‹è½½é€Ÿåº¦: {downloads['aria2_download_speed_mbs'].max():.2f} MB/s")
    print(f"æœ€æ…¢ä¸‹è½½é€Ÿåº¦: {downloads['aria2_download_speed_mbs'].min():.2f} MB/s")
print()

# æœ€è¿‘ 10 æ¡è®°å½•
print("=== æœ€è¿‘ 10 æ¡è®°å½• ===")
for _, row in df.tail(10).iterrows():
    cache_status = "HIT " if row['cache_hit'] else "MISS"
    print(f"[{cache_status}] {row['package_name'][:50]:<50} | {row['file_size_mb']:>7.2f}MB | {row['total_time']:>6.3f}s")
```

### è¿è¡Œåˆ†æ

```bash
python view_metrics.py
```

---

## ğŸ¯ å¸¸ç”¨åœºæ™¯

### 1. ç›‘æ§å®æ—¶ä¸‹è½½

**åœºæ™¯**ï¼šæµ‹è¯•æ—¶å®æ—¶æŸ¥çœ‹ä¸‹è½½æƒ…å†µ

```bash
# Windows
docker-compose logs -f lightmirrors | Select-String "METRICS|Aria2"

# Linux/Mac
docker-compose logs -f lightmirrors | grep -E "METRICS|Aria2"
```

### 2. æŸ¥æ‰¾ç‰¹å®šåŒ…çš„ä¸‹è½½è®°å½•

**åœºæ™¯**ï¼šæŸ¥çœ‹ numpy åŒ…çš„ä¸‹è½½å†å²

Windows:
```powershell
Get-Content data\metrics\metrics.json | ConvertFrom-Json | Where-Object { $_.package_name -like "*numpy*" }
```

Linux/Mac:
```bash
cat data/metrics/metrics.json | jq '.[] | select(.package_name | contains("numpy"))'
```

### 3. ç»Ÿè®¡ä»Šå¤©çš„ç¼“å­˜å‘½ä¸­ç‡

**åœºæ™¯**ï¼šæŸ¥çœ‹ä»Šå¤©çš„é•œåƒæ•ˆæœ

Python:
```python
import json
from datetime import date

with open('data/metrics/metrics.json', 'r') as f:
    data = json.load(f)

today = date.today().isoformat()
today_records = [r for r in data if r['timestamp'].startswith(today)]
hit_rate = sum(1 for r in today_records if r['cache_hit']) / len(today_records) * 100
print(f"ä»Šå¤©çš„ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.1f}%")
```

### 4. å¯¼å‡ºä¸º CSV

**åœºæ™¯**ï¼šå¯¼å‡ºåˆ° Excel åˆ†æ

```python
import json
import pandas as pd

with open('data/metrics/metrics.json', 'r') as f:
    data = json.load(f)

df = pd.DataFrame(data)
df.to_csv('metrics_export.csv', index=False, encoding='utf-8-sig')
print("å·²å¯¼å‡ºåˆ° metrics_export.csv")
```

### 5. æŒç»­ç›‘æ§ï¼ˆè‡ªåŠ¨åˆ·æ–°ï¼‰

**åœºæ™¯**ï¼šç»ˆç«¯æŒç»­æ˜¾ç¤ºæœ€æ–°æ—¥å¿—

Windows PowerShell:
```powershell
while ($true) {
    Clear-Host
    docker-compose logs --tail 20 lightmirrors | Select-String "METRICS"
    Start-Sleep -Seconds 2
}
```

Linux/Mac:
```bash
watch -n 2 'docker-compose logs --tail 20 lightmirrors | grep METRICS'
```

---

## âš ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šæ²¡æœ‰æ—¥å¿—è¾“å‡º

**æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œï¼š**
```bash
docker-compose ps
```

**æ£€æŸ¥å®¹å™¨æ—¥å¿—ï¼š**
```bash
docker-compose logs lightmirrors
```

### é—®é¢˜ 2ï¼šJSON æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨

**æ£€æŸ¥ç›®å½•æƒé™ï¼š**
```bash
ls -la data/metrics/
```

**åœ¨å®¹å™¨å†…æ£€æŸ¥ï¼š**
```bash
docker-compose exec lightmirrors ls -la /app/data/
docker-compose exec lightmirrors cat /app/data/metrics.json
```

**é‡æ–°åˆå§‹åŒ–ï¼š**
```bash
# åœæ­¢æœåŠ¡
docker-compose down

# ç¡®ä¿ç›®å½•å­˜åœ¨
mkdir -p data/metrics

# é‡å¯æœåŠ¡
docker-compose up -d
```

### é—®é¢˜ 3ï¼šæ—¥å¿—è¿‡å¤šéš¾ä»¥æŸ¥çœ‹

**åªçœ‹ METRICS ç›¸å…³ï¼š**
```bash
docker-compose logs lightmirrors 2>&1 | grep METRICS
```

**ä¿å­˜åˆ°æ–‡ä»¶ï¼š**
```bash
docker-compose logs lightmirrors > logs_$(date +%Y%m%d).txt
```

---

## ğŸ’¡ æ¨èå·¥ä½œæµ

1. **å¯åŠ¨æœåŠ¡åï¼Œå¼€ä¸¤ä¸ªç»ˆç«¯**ï¼š
   - ç»ˆç«¯ 1ï¼š`docker-compose logs -f lightmirrors | grep METRICS`ï¼ˆå®æ—¶ç›‘æ§ï¼‰
   - ç»ˆç«¯ 2ï¼šæ­£å¸¸æ“ä½œï¼ˆæµ‹è¯•ä¸‹è½½ç­‰ï¼‰

2. **å®šæœŸæŸ¥çœ‹ JSON æ•°æ®**ï¼š
   ```bash
   cat data/metrics/metrics.json | jq '.[-10:]'  # æŸ¥çœ‹æœ€è¿‘ 10 æ¡
   ```

3. **æ¯å¤©åˆ†æä¸€æ¬¡**ï¼š
   ```bash
   python view_metrics.py  # è¿è¡Œç»Ÿè®¡è„šæœ¬
   ```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [é‡åŒ–æ•°æ®è¯´æ˜](../data/metrics/README.md)
- [å¿«é€Ÿå¼€å§‹æŒ‡å—](./QUICK_START.md)
- [ç¼“å­˜ç®¡ç†æŒ‡å—](./CACHE_MANAGEMENT.md)

